\documentclass[twocolumn]{article}
\usepackage{amsmath}
\usepackage[pdfusetitle]{hyperref}
\usepackage[a4paper, total={6in, 8in}]{geometry}
\usepackage{microtype}
\usepackage{mathtools}

\title{STAT PHYS SCIENCE Midterm Cheat Sheet}
\author{Noppakorn Jiravaranun}
\date{\today}

\newcommand\Perm[2][^n]{\prescript{#1\mkern-2.5mu}{}P_{#2}}
\newcommand\Comb[2][^n]{\prescript{#1\mkern-0.5mu}{}C_{#2}}

\begin{document}
\maketitle
\section{Measure of Central Tendency}
\subsection{Mean}
\begin{equation}
    \mu = \frac{\sum_{i=1}^{N}x_{i}}{N}
\end{equation}
\begin{equation}
    \bar{x} = \frac{\sum_{i=1}^{n}x_{i}}{n}
\end{equation}
\subsection{Median}
\begin{equation}
    M = x_{(\frac{N+1}{2})}
\end{equation}
\section{Quantiles}
\subsection{Quartiles}
\begin{equation}
    Q_{i} = x_{(i(\frac{N+1}{4}))}
\end{equation}
\subsection{Deciles}
\begin{equation}
    D_{i} = x_{(i(\frac{N+1}{10}))}
\end{equation}
\subsection{Percentiles}
\begin{equation}
    P_{i} = x_{(i(\frac{N+1}{100}))}
\end{equation}

\newpage

\section{Measurement of Variation or Dispersion}
\subsection{Range}
\begin{equation}
    R = x_{max} - x_{min}
\end{equation}
\subsection{Average Deviation (A.D.)}
\begin{equation}
    A.D. = \frac{\sum_{i=1}^{n} |x_{i}-\mu|}{n}
\end{equation}
\subsection{Standard Deviation (S.D.)}
\subsubsection{Standard Deviation (Population)}
\begin{equation}
    \sigma = \sqrt{\frac{\sum_{i=1}^{N} (x_{i}-\mu)^2}{N}} = \sqrt{\frac{\sum_{i=1}^{N} x_{i} -N\mu^2}{N}}
\end{equation}
\subsubsection{Standard Deviation (Sample)}
\begin{equation}
    s = \sqrt{\frac{\sum_{i=1}^{n} (x_{i}-\mu)^2}{n-1}} = \sqrt{\frac{\sum_{i=1}^{n} x_{i} -N\mu^2}{n-1}}
\end{equation}
\subsection{Quatile Deviation}
\begin{equation}
    Q.D. = \frac{Q_{3} - Q_{1}}{2}
\end{equation}

\newpage

\subsection{Skewness}
\subsubsection{Skewness (Population)}
\begin{equation}
    S_{k} = \sum_{i=1}^{N}\frac{[x_{i} - \mu]^{3}}{\sigma^{3}N}
\end{equation}
if $S_{k} = 0$ the data is normal\\
else if $S_{k} > 0$ the data is skwed right\\
else if $S_{k} < 0$ the data is skwed left
\subsubsection{Skewness (Sample)}
\begin{equation}
    s_{k} = \sum_{i=1}^{n}\frac{[x_{i} - \bar{x}]^{3}}{s^{3}n}
\end{equation}
if $-1 \leq s_{k} \leq 1$ the data is normal\\
else if $s_{k} > 1$ the data is skwed right\\
else if $s_{k} < -1$ the data is skwed left
\subsection{Relative Kurtosis}
A measure of the peakedness of a distribution
\subsubsection{Relative Kurtosis (Population)}
\begin{equation}
    K = \sum_{i=1}^{N}\frac{[x_{i} - \mu]^{4}}{\sigma^{4}N} - 3
\end{equation}
if $K = 0$ the data is normal\\
else if $K > 0$ the data is higher than normal\\
else if $K < 0$ the data is lower than normal
\subsubsection{Relative Kurtosis (Sample)}
\tiny
\begin{equation}
    k = \frac{n^{2}(n+1)}{(n-1)(n-2)(n-3)} \sum_{i=1}^{n}\frac{[x_{i}-x]^{4}}{s^{4}n}-\frac{3(n-1)^{2}}{(n-2)(n-3)}
\end{equation}
\normalsize
if $-1 \leq k \leq 1$ the data is normal\\
else if $k > 1$ the data is higher than normal\\
else if $k < -1$ the data is lower than normal
\section{Coefficient of Variation}
\begin{equation}
    C.V. = \frac{\sigma}{\mu} \times 100\%
\end{equation}
\begin{equation}
    C.V. = \frac{s}{\bar{x}} \times 100\%
\end{equation}

\newpage

\section{Outlier by Box Plot}
\subsection{Inter Quartile Range}
\begin{equation}
    IQR = Q_{3}-Q_{1}
\end{equation}
\subsection{Whisker}
Whisker is the highest or lowest value not reaching the Inner Fence.
\subsection{Fence}
Outlier is the value lower or higher than the Outer Fence.\\
Suspected Outlier is the value between the Inner Fence and the Outer Fence.
\begin{equation}
    Outer\ Fence = Q_{1} - 3(IQR)
\end{equation}
\begin{equation}
    Inner\ Fence = Q_{1} - 1.5(IQR)
\end{equation}
\begin{equation}
    Inner\ Fence = Q_{3} + 1.5(IQR)
\end{equation}
\begin{equation}
    Outer\ Fence = Q_{3} + 3(IQR)
\end{equation}
\section{Probability}
\subsection{Permutation}
\begin{equation}
    \Perm[n]{r} = \frac{n!}{(n-r)!}
\end{equation}
\subsection{Combination}
\begin{equation}
    \Comb[n]{r} = \binom{n}{r} = \frac{n!}{r!(n-r)!}
\end{equation}
\subsection{Properties of Probability}
\begin{itemize}
    \item $0 \leq P(A) \leq 1$
    \item $P(\emptyset) = 0$
    \item $P(S) = 1$
    \item $P(A \cup B) = P(A) + P(B) - P(A \cap B)$
    \item $P(A) = 1 - P(A)'$
\end{itemize}
\subsection{Conditional Probability}
\begin{equation}
    P(A|B) = \frac{P(A \cap B)}{P(B)}
\end{equation}
\subsection{Joint Probability}
\begin{equation}
    P(A \cap B) = P(A)P(B|A)
\end{equation}
\begin{equation}
    P(A \cap B) = P(B)P(A|B)
\end{equation}
\begin{equation}
    P(A \cap B \cap C) = P(A \cap B)P(C|(A \cap B)) 
\end{equation}
\begin{equation}
    P(A \cap B \cap C) = P(A)P(B|A)P(C|(A \cap B))
\end{equation}
\section{Probability Distribution}
\subsection{Probability Mass Function}
\begin{equation}
    f(x) \geq 0;\ for\ all\ x
\end{equation}
\begin{equation}
    \sum_{all x} f(x) = 1
\end{equation}
\begin{equation}
    F(x) = P(X \leq x) = \sum_{all\ x \in [-\infty,x]} f(x)
\end{equation}
\begin{equation}
    \mu = E(X) = \sum_{all\ x} xf(x)
\end{equation}
\begin{equation}
    \sigma^{2} = V(X) = \sum_{all\ x} x^{2}f(x) - \mu^{2}
\end{equation}

\subsection{Probability Density Function}
\begin{equation}
    f(x) \geq 0;\ for\ all\ x
\end{equation}
\begin{equation}
    \int_{-\infty}^{\infty} f(x) = 1
\end{equation}
\begin{equation}
    F(x) = P(X \leq x) = \int_{-\infty}^{x} f(y)dy
\end{equation}
\begin{equation}
    \mu = E(X) = \int_{-\infty}{\infty} xf(x)
\end{equation}
\begin{equation}
    \sigma^{2} = V(X) = \int_{-\infty}^{\infty} x^{2}f(x) - \mu^{2}
\end{equation}

\section{Probability Function}
\subsection{Uniform Distribution}
\begin{equation}
    f(x) = \frac{1}{k}
\end{equation}
\begin{equation}
    \mu = \frac{1}{k} \sum_{i=1}^{k} x_{i}\ \ 
    \sigma^{2} = \frac{1}{k} \sum_{i=1}^{k} (x_{i}-\mu)^{2}
\end{equation}
\subsection{Binomial Distribution}
\begin{equation}
    f(x) = \Comb[n]{x} p^{x}(n-p)^{1-x}; x = 0,1,2,...,n
\end{equation}
\begin{equation}
    \mu = np\ \ 
    \sigma^{2} = np(1-p)
\end{equation}
\subsection{Negative Binomial Distribution}
\begin{equation}
    f(x) = \binom{x-1}{r-1}(1-p)^{x-r}p^{r}
\end{equation}
\begin{center}
    $x = r,r+1,r+2,...$
\end{center}
\begin{equation}
    \mu = E(X) = \frac{r}{p}
\end{equation}
\begin{equation}
    \sigma^{2} = V(X) = \frac{r(1-p)}{p^{2}}
\end{equation}
Geometric Distribution $(r = 1)$
\begin{equation}
    f(x) = p(1-p)^{x-1}; x = 1,2,...
\end{equation}
\begin{equation}
    \mu = E(X) = \frac{1}{p}
\end{equation}
\begin{equation}
    \sigma^{2} = V(X) = \frac{(1-p)}{p^{2}}
\end{equation}
\subsection{Poisson Distribution}
\begin{equation}
    f(x) = \frac{e^{-\mu}\mu^{x}}{x!}
\end{equation}
\begin{equation}
    \sigma^2 = \mu
\end{equation}
\subsection{Hypergeometric Distribution}
\begin{equation}
    f(x) = \frac{{\binom{K}{x}}{\binom{N-K}{n-x}}}{\binom{N}{n}}
\end{equation}
\begin{equation}
    \mu = E(X) = np
\end{equation}
\begin{equation}
    \sigma^{2} = V(X) = np(1-p)\frac{N-n}{N-1}
\end{equation}

\end{document}
